import  requests
from lxml import html
import time
import traceback
import os

def concat_url(url,n):

    for i in range(1,n+1):
        # url_Now=url+'/tech/pn'+str(i)
        url_Now='https://bj.58.com/tech/?PGTID=0d202408-0000-1054-159a-a5271c9729c3&ClickID=4'
        print("正在爬取：",url_Now)
        get_Links(url_Now,n+1)

def get_Links(rooturl,Name):
    headers=header()
    time.sleep(10)
    r = requests.get(url, headers=headers)
    r.encoding='utf8'
    print(r.text)
    with open(str(Name)+".html", 'w', encoding="utf8") as baiduFile:
        baiduFile.write(r.text)


def getLinks(txt):
    global name
    global url_h
    content = txt
    content = content.replace('<!--', '').replace('-->', '')
    LISTtree = html.etree.HTML(content)
    links = LISTtree.xpath('//div[@class="job_name clearfix"]/a/@href')
    for link in links:
        name = link[link.rfind('/') + 1:link.rfind('.')]
        url = url_h + link
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Mobile Safari/537.36'
            }
            r = requests.get(url, headers=headers)
            r.encoding = 'utf8'
            # print(r.text)
            htmlTXT = r.text
            getPicLINK(htmlTXT)

            except Exception as e:
                with open("errorLog.txt", "a+", encoding="utf8") as f1:
                    f1.write(getNowTime() + "-- " + traceback.format_exc() + '\n')
                    print(getNowTime() + "-- " + traceback.format_exc() + '\n')
                print('错误getLinks')
                continue








def header():
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
        'Accept-Encoding': 'gzip, deflate, br',
        'Accept-Language': 'zh-CN,zh;q=0.9'
    }
    return headers










if __name__ == '__main__':
    url='https://bj.58.com/tech/?PGTID=0d202408-0000-1054-159a-a5271c9729c3&ClickID=4'
    pages=int(input("请输入要爬取几页："))
    concat_url(url, pages)

    print("完成")
